\section{Описание}

Так как я брал дамп русской Википедии и на его основе генерировал простые html-страницы, над структурой этих страниц и их содержимом думать не придётся. Однако есть ряд моментов, которые стоит учесть при токенизации:

\begin{enumerate}
    \item исключить все html-теги, благо их не так много;
    \item исключить все ссылки (прим. https://ru.wikipedia.org/wiki/Заглавная\_страница);
    \item исключить различную техническую информацию от самой Википидии (прим. "[[категория: Международные договоры XX века]]" или == Известные носители ==);
    \item исключить различные числа и даты, чтобы не захломлять индекс.
\end{enumerate}

Касательно дат - их по-хорошему наверное стоит оставить, но я посчитал это лишним, так как довольно мала вероятность, что кто-то будет искать что-то по дате. 

Также я учитывал ещё и ряд других ситуаций, но по памяти довольно сложно всё в точности упомянуть.

Парсинг реализовал на Python при помощи регулярных выражений. Это первый опыт их использования, потому что ранее не было особых причин.

Время работы токенизации - 40 минут 24 секунды.\\
Время работы на один килобайт текста - $3.2154 * 10^{-4}$ \\
Количество уникальных токенов - 3,434,138.\\
Всего токенов - 141,154,824
Средняя длина токена - 8.34 символа.

Уверен, что это не достаточно оптимальное время. Причина в том, что в своей реализации я использую несколько различных регулярных выражений вместо одного. Из-за этого моя реализация по сути проходит по тексту несколько раз вместо одного. Я побоялся писать одно массивное регулярное выражение, опасаясь возможных проблем с отладкой.

\pagebreak

\section{Исходный код}
Токенизатор:
\begin{lstlisting}[language=Python]
from bs4 import BeautifulSoup
from sys import argv
import re
import os
import time
from collections import Counter

total_tokens = Counter()

def ExtractTokens(filename):
    html_content = ""
    
    with open(filename, "r") as file:
        html_content = file.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        text = soup.find_all(text=True)
        title = soup.h1.text
        output = ''

        blacklist = [
            '[document]',
            'noscript',
            'header',
            'html',
            'meta',
            'head', 
            'input',
            'script',
        ]

        # skips = [
        #     '\n', '|', '=', 'http://', '[', ']', '{', '}', '\\', '*', '_', '/', '.', ','
        # ]

        for t in text:
            if t.parent.name not in blacklist:
                output += '{} '.format(t)

        output = output.lower()
        reg = re.compile(' //.*?\n')
        output = reg.sub('', output)
        output = output.replace("\n", " ")

        counter = 0
        tmp = ''
        for ch in output:
            if ch == '{':
                counter += 1
            elif ch == '}':
                counter -= 1
            elif counter < 2:
                tmp += ch
        output = tmp

        regexp_rules = [
            '\[\[(категория:|file:).*?]]',
            '==.*?==',
            '\[http.*?]',
            '[^0-9 а-яё-]',
            '\d+\D*? ',
            '\s+',
            '  '
        ]
        for rule in regexp_rules:
            reg = re.compile(rule)
            output = reg.sub(' ', output)

        # reg = re.compile(' (.|..|...) ')
        # for i in range(5):
        #     output = reg.sub(' ', output)

        counter = Counter(output.split())
        total_tokens.update(counter)

        fileToSave = filename[:-4] + "data"
        i = -1
        while fileToSave[i] != '/':
            i = i - 1

        fileToSave = os.path.join(fileToSave[:i], "data", fileToSave[i+1:])

        if not os.path.exists(fileToSave[:i]):
            os.makedirs(fileToSave[:i])
        with open(fileToSave, "w") as save:
            save.write(title + "\n")
            for key, value in counter.items():
                save.write(key + "\n" + str(value) + "\n")

def main():
    if len(argv) > 1:
        roots = []
        for arg in argv:
            if arg == argv[0]:
                continue
            roots.append(arg)
            
        for root in roots:
            if not os.path.exists(os.path.join(root, "html")):
                os.makedirs(os.path.join(root, "html"))
            
            if not os.path.exists(os.path.join(root, "data")):
                os.makedirs(os.path.join(root, "data"))

            onlyfiles = [f for f in os.listdir(os.path.join(root, "html")) if os.path.isfile(os.path.join(root, "html", f))]
            for file in onlyfiles:
                print("\33[2K\rReplace old html to root... " + os.path.join(root, "html", file) + " to " + os.path.join(root, file), end="")
                os.replace(os.path.join(root, "html", file), os.path.join(root, file))
            print("")

            for filename in os.listdir(os.path.join(root, "data")):
                print("\33[2K\rRemove old .data files... " + os.path.join(root, "data", filename), end="")
                file_path = os.path.join(root, "data", filename)
                try:
                    if os.path.isfile(file_path) or os.path.islink(file_path):
                        os.unlink(file_path)
                except Exception as e:
                    print('Failed to delete %s. Reason: %s' % (file_path, e))
            print("")

            print("Start extract...")
            print("========================")
            onlyfiles = [f for f in os.listdir(root) if os.path.isfile(os.path.join(root, f))]
            begin_time = time.time()
            tm_hour    = 0
            tm_min     = 0
            tm_sec     = 0
            for file in onlyfiles:
                delta_time = time.gmtime(time.time() - begin_time)
                tm_hour    = delta_time.tm_hour
                tm_min     = delta_time.tm_min
                tm_sec     = delta_time.tm_sec
                print("\33[2K\r| Total time: {hour:02d}:{min:02d}:{sec:02d} | Extract {path}...".format(hour=tm_hour, min=tm_min, sec=tm_sec, path=os.path.join(root, file)), end="")
                ExtractTokens(os.path.join(root, file))
                os.replace(os.path.join(root, file), os.path.join(root, "html", file))
            print("\33[2K\r| Total time: {hour:02d}:{min:02d}:{sec:02d} |".format(hour=tm_hour, min=tm_min, sec=tm_sec))
            print("========================")
        
        print("Total token count: {total:13d}".format(total=len(total_tokens)))

    else:
        print("Example usage: python " + argv[0] + " [dir_path...]")

if __name__ == "__main__":
    main()
\end{lstlisting}

Скрипт для подсчёта количества токенов и их средней длины:
\begin{lstlisting}[language=Python]
from sys import argv, stdout
import os
import time

def main():
    if len(argv) > 1:
        roots = []
        for arg in argv:
            if arg == argv[0]:
                continue
            roots.append(arg)
        
        total_len = 0
        count_token = 0
        avg = 0.0

        for root in roots:
            if not os.path.exists(os.path.join(root, "data")):
                os.makedirs(os.path.join(root, "data"))

            begin_time = time.time()
            tm_hour    = 0
            tm_min     = 0
            tm_sec     = 0
            onlyfiles = [f for f in os.listdir(os.path.join(root, "data")) if os.path.isfile(os.path.join(root, "data", f))]
            for filename in onlyfiles:
                delta_time = time.gmtime(time.time() - begin_time)
                tm_hour    = delta_time.tm_hour
                tm_min     = delta_time.tm_min
                tm_sec     = delta_time.tm_sec
                with open(os.path.join(root, "data", filename), "r") as file:
                    i = 0
                    for line in file:
                        if i == 0:
                            i = 1
                            continue
                        if i % 2 == 1:
                            count_token += 1
                            total_len   += len(line)
                            avg = total_len / count_token
                            print("\r| Total time: {hour:02d}:{min:02d}:{sec:02d} | Tokens = {tokens:10d}, Avg_len  {agv_len:10.5f} | Check {path}... {line}".format(hour=tm_hour, min=tm_min, sec=tm_sec, path=os.path.join(root, filename), line=line, tokens=count_token, agv_len=avg), end="")
                            stdout.flush()
                        i += 1
            
            avg = total_len / count_token
            print("\33[2K\r| Total time: {hour:02d}:{min:02d}:{sec:02d} | Tokens = {tokens:10d}, Avg_len  {agv_len:10.5f}".format(hour=tm_hour, min=tm_min, sec=tm_sec, tokens=count_token, agv_len=avg))
            print("========================")

    else:
        print("Example usage: python " + argv[0] + " [dir_path...]")

if __name__ == "__main__":
    main()
\end{lstlisting}

\pagebreak

